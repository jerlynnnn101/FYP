# RAG pipeline mode: set to 'cookbook' to use Docling + LangChain RetrievalQA
RAG_PIPELINE_MODE=cookbook

# IBM Watsonx config (placeholders — put real values in .env, not here)
WATSONX_URL=https://us-south.ml.cloud.ibm.com
IBM_PROJECT_ID=your-project-id
WATSONX_API_KEY=your-api-key

# Optional: set an embeddings model when available in your region/project
WATSONX_EMBED_MODEL=ibm/granite-embedding-107m-multilingual
# Granite instruct model used for generation (cookbook path)
GRANITE_MODEL_ID=ibm/granite-3-8b-instruct

# Flask
PORT=5001

# Local embeddings (preferred for offline vector search)
SENTENCE_TRANSFORMER_MODEL=sentence-transformers/all-MiniLM-L6-v2

# IBM Cloud Object Storage (for uploaded documents) — placeholders
COS_ENDPOINT=https://s3.us-south.cloud-object-storage.appdomain.cloud
COS_ACCESS_KEY_ID=your-hmac-access-key
COS_SECRET_ACCESS_KEY=your-hmac-secret-key
COS_BUCKET=your-bucket-name

# Set to true to only use the most recent document version
RAG_CURRENT_ONLY=true
